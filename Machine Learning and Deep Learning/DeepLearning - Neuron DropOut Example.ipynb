{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b4a9f1",
   "metadata": {},
   "source": [
    "# Neuron DropOut Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35883d3",
   "metadata": {},
   "source": [
    "**In DeepLearning sometimes we tend to over apply the training in a way that we overfit the model. In this notebook I will try to prove that Neuron DropOut can make a model more accuarate in the end. The example will use tensorflow with keras and digits dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eedecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27aad9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391eeb84",
   "metadata": {},
   "source": [
    "**First Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03441df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(25, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8aaf2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332a9241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 1.0194 - accuracy: 0.8166\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2704 - accuracy: 0.9256\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1892 - accuracy: 0.9465\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1557 - accuracy: 0.9547\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1340 - accuracy: 0.9624\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1205 - accuracy: 0.9656\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1013 - accuracy: 0.9710\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0955 - accuracy: 0.9721\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0825 - accuracy: 0.9764\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0757 - accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1352c8b0760>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb5b707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 675us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.99      0.47       980\n",
      "           1       0.35      0.99      0.51      1135\n",
      "           2       0.16      0.03      0.06      1032\n",
      "           3       0.48      0.35      0.40      1010\n",
      "           4       0.35      0.18      0.24       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.61      0.06      0.12       958\n",
      "           7       0.53      0.02      0.04      1028\n",
      "           8       0.98      0.78      0.87       974\n",
      "           9       0.95      0.38      0.54      1009\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.57      0.47      0.42     10000\n",
      "weighted avg       0.56      0.47      0.41     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import numpy as np\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f1b730",
   "metadata": {},
   "source": [
    "**As we can see in the classification report our model was not so good as the epochs accuaracy parameter tended to show, their we got 97.8% accuracy, but with the tests our overall accuracy (f1-score) was only 47%.**\n",
    "**With that we can conclude that First Model was not very good at all. Now let's try to use drop-out technique to improve our f1-score in a second model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c11529",
   "metadata": {},
   "source": [
    "**DropOut Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4331d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDropOut = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(25, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aab340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDropOut.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795d72e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 2.8803 - accuracy: 0.3189\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.5217 - accuracy: 0.4512\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2124 - accuracy: 0.5672\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.0127 - accuracy: 0.6382\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.9076 - accuracy: 0.6763\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8572 - accuracy: 0.6914\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8194 - accuracy: 0.7042\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7903 - accuracy: 0.7119\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7684 - accuracy: 0.7201\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7437 - accuracy: 0.7310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1352fb1af50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDropOut.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47793c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 696us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       980\n",
      "           1       0.99      0.98      0.98      1135\n",
      "           2       0.50      0.88      0.64      1032\n",
      "           3       0.93      0.88      0.91      1010\n",
      "           4       0.94      0.85      0.89       982\n",
      "           5       0.91      0.76      0.83       892\n",
      "           6       0.94      0.95      0.94       958\n",
      "           7       0.96      0.92      0.94      1028\n",
      "           8       0.32      0.08      0.13       974\n",
      "           9       0.78      0.93      0.85      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.82      0.82      0.80     10000\n",
      "weighted avg       0.82      0.83      0.81     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = modelDropOut.predict(x_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f23cacb",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "**As we can see when doing the epochs we got the impression that our accuracy in 'modelDropOut' would be lesser then in 'model', but when we run our classification report we discover the contraty. The non-dropout model got an f1-score of 47% and the dropout model got an f1-score of 83%, way better then the first other model. With that we can check how the DropOut technique improves alot the accuracy in a model reducing it's overfitting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a33bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
