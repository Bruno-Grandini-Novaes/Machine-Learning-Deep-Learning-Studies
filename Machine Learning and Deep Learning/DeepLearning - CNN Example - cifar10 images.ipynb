{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da765976",
   "metadata": {},
   "source": [
    "# CNN Example - cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997624ca",
   "metadata": {},
   "source": [
    "**In this example we are gonna to train a CNN(Convolutional Neural Network). Forthat we are gonna to use the cifar10 dataset, with is a collection of many images, with different classes, all in 32px by 32px RGB format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c665892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22c13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640a66f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6c302",
   "metadata": {},
   "source": [
    "**Here as we can see we are dealing with a great amount of images to train, 50.000. All images in 32 by 32 pixels, in RGB(3) channel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5d52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689459ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23137255, 0.24313725, 0.24705882],\n",
       "        [0.16862745, 0.18039216, 0.17647059],\n",
       "        [0.19607843, 0.18823529, 0.16862745],\n",
       "        ...,\n",
       "        [0.61960784, 0.51764706, 0.42352941],\n",
       "        [0.59607843, 0.49019608, 0.4       ],\n",
       "        [0.58039216, 0.48627451, 0.40392157]],\n",
       "\n",
       "       [[0.0627451 , 0.07843137, 0.07843137],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.07058824, 0.03137255, 0.        ],\n",
       "        ...,\n",
       "        [0.48235294, 0.34509804, 0.21568627],\n",
       "        [0.46666667, 0.3254902 , 0.19607843],\n",
       "        [0.47843137, 0.34117647, 0.22352941]],\n",
       "\n",
       "       [[0.09803922, 0.09411765, 0.08235294],\n",
       "        [0.0627451 , 0.02745098, 0.        ],\n",
       "        [0.19215686, 0.10588235, 0.03137255],\n",
       "        ...,\n",
       "        [0.4627451 , 0.32941176, 0.19607843],\n",
       "        [0.47058824, 0.32941176, 0.19607843],\n",
       "        [0.42745098, 0.28627451, 0.16470588]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.81568627, 0.66666667, 0.37647059],\n",
       "        [0.78823529, 0.6       , 0.13333333],\n",
       "        [0.77647059, 0.63137255, 0.10196078],\n",
       "        ...,\n",
       "        [0.62745098, 0.52156863, 0.2745098 ],\n",
       "        [0.21960784, 0.12156863, 0.02745098],\n",
       "        [0.20784314, 0.13333333, 0.07843137]],\n",
       "\n",
       "       [[0.70588235, 0.54509804, 0.37647059],\n",
       "        [0.67843137, 0.48235294, 0.16470588],\n",
       "        [0.72941176, 0.56470588, 0.11764706],\n",
       "        ...,\n",
       "        [0.72156863, 0.58039216, 0.36862745],\n",
       "        [0.38039216, 0.24313725, 0.13333333],\n",
       "        [0.3254902 , 0.20784314, 0.13333333]],\n",
       "\n",
       "       [[0.69411765, 0.56470588, 0.45490196],\n",
       "        [0.65882353, 0.50588235, 0.36862745],\n",
       "        [0.70196078, 0.55686275, 0.34117647],\n",
       "        ...,\n",
       "        [0.84705882, 0.72156863, 0.54901961],\n",
       "        [0.59215686, 0.4627451 , 0.32941176],\n",
       "        [0.48235294, 0.36078431, 0.28235294]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6915b51",
   "metadata": {},
   "source": [
    "**Now we just normalized the data. Initially it was with values between 0 and 255. The normalization will improve our model results. Now the possible features will be all 0 to 1 values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b60cb6",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network Training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f7bb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=(2,2), activation='relu', input_shape = (32, 32, 3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(250, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa722d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a701a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.5882 - accuracy: 0.4161\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.2243 - accuracy: 0.5663\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.0765 - accuracy: 0.6218\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.9705 - accuracy: 0.6607\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.8993 - accuracy: 0.6876\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.8395 - accuracy: 0.7062\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7864 - accuracy: 0.7255\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.7409 - accuracy: 0.7395\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6924 - accuracy: 0.7574\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6592 - accuracy: 0.7672\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6204 - accuracy: 0.7832\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5899 - accuracy: 0.7909\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5658 - accuracy: 0.8007\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5401 - accuracy: 0.8079\n",
      "Epoch 15/15\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5132 - accuracy: 0.8185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27c5930ddb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88627f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.79      0.72      1000\n",
      "           1       0.80      0.85      0.83      1000\n",
      "           2       0.61      0.57      0.59      1000\n",
      "           3       0.51      0.54      0.52      1000\n",
      "           4       0.70      0.58      0.63      1000\n",
      "           5       0.66      0.53      0.59      1000\n",
      "           6       0.80      0.76      0.78      1000\n",
      "           7       0.76      0.78      0.77      1000\n",
      "           8       0.82      0.79      0.81      1000\n",
      "           9       0.71      0.84      0.77      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.70     10000\n",
      "weighted avg       0.70      0.70      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab93f1",
   "metadata": {},
   "source": [
    "**With that we were able to make a model with 70% f1-score**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
